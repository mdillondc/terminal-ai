# Terminal AI Configuration Example
# Copy this file to ~/.config/terminal-ai/config and customize as needed
# Lines starting with # are comments and will be ignored

# This file is optional
# If file does not exist or file exists but is missing some settings
# the app will use defaults from settings_manager.py

# This is a SMALL sample
# See `settings_manager.py` for all available settings.

# =============================================================================
# API SETTINGS
# =============================================================================

# Default AI model to use
# model = gemini-2.5-flash
# model = llama3.1:8b

# Ollama server URL (if using Ollama models)
# ollama_base_url = http://localhost:11434

# =============================================================================
# RAG (RETRIEVAL AUGMENTED GENERATION) SETTINGS
# =============================================================================

# embedding_provider = ollama

# Ollama embedding model (recommended for local privacy)
# ollama_embedding_model = snowflake-arctic-embed2:latest

# OpenAI embedding model (requires API key and sends data to OpenAI)
# openai_embedding_model = text-embedding-3-small

# ...
# SEE settings_manager.py FOR ALL AVAILABLE SETTINGS